{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Foundation of Machine Learning**\n",
    "##### **Final Project**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step1**\n",
    "\n",
    "- We found a celebrity dataset in huggingface. \n",
    "- Install huggingface cli to use the dataset\n",
    "```\n",
    "pip install -U \"huggingface_hub[cli]\"\n",
    "huggingface-cli --help\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: The dataset for celebrity images were found from the following repo in huggingface. \n",
    "```\n",
    "https://huggingface.co/datasets/ares1123/celebrity_dataset\n",
    "```\n",
    "Thanks to user **https://huggingface.co/ares1123**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Step 2: Download the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['image', 'label'],\n",
      "        num_rows: 18184\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ares1123/celebrity_dataset\")\n",
    "print(dataset)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* View Dataset loaded as pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18179</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18180</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18181</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18182</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18183</th>\n",
       "      <td>{'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...</td>\n",
       "      <td>996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18184 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   image  label\n",
       "0      {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "1      {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "2      {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "3      {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "4      {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...      0\n",
       "...                                                  ...    ...\n",
       "18179  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    996\n",
       "18180  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    996\n",
       "18181  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    996\n",
       "18182  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    996\n",
       "18183  {'bytes': b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x...    996\n",
       "\n",
       "[18184 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_parquet(\"hf://datasets/ares1123/celebrity_dataset/data/train-00000-of-00001.parquet\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=256x256 at 0x20A605A2BD0>, 'label': 0}\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Save images as jpg from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "def save_dataset_images(dataset, label_mapping_csv, output_base_dir='dataset_images'):\n",
    "    \"\"\"\n",
    "    Save images from a Hugging Face dataset to folders named using a CSV label mapping.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataset: Hugging Face dataset\n",
    "    - label_mapping_csv: Path to CSV file with label mapping\n",
    "    - output_base_dir: Base directory to save images\n",
    "    \n",
    "    Returns:\n",
    "    - Path to the created output directory\n",
    "    \"\"\"\n",
    "    # Read the label mapping CSV\n",
    "    try:\n",
    "        label_mapping_df = pd.read_csv(label_mapping_csv)\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Error reading label mapping CSV: {e}\")\n",
    "    \n",
    "    # Create a dictionary mapping integer labels to names\n",
    "    # Assumes the CSV has columns for integer label and corresponding name\n",
    "    # You might need to adjust column names based on your specific CSV structure\n",
    "    try:\n",
    "        label_map = dict(zip(label_mapping_df['Label'], label_mapping_df['Name']))\n",
    "    except KeyError:\n",
    "        raise ValueError(\"CSV must contain 'Label' and 'Name' columns\")\n",
    "    \n",
    "    # Ensure output directory exists\n",
    "    os.makedirs(output_base_dir, exist_ok=True)\n",
    "    \n",
    "    # Create a list to track saved images\n",
    "    saved_images = []\n",
    "    \n",
    "    # Iterate through the dataset\n",
    "    for idx, item in enumerate(dataset):\n",
    "        # Get image and integer label\n",
    "        img = item['image']\n",
    "        label = item['label']\n",
    "        \n",
    "        # Get the name from the label mapping\n",
    "        try:\n",
    "            label_name = label_map[label]\n",
    "        except KeyError:\n",
    "            print(f\"Warning: No mapping found for label {label}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Create label-specific folder using the mapped name\n",
    "        label_dir = os.path.join(output_base_dir, label_name)\n",
    "        os.makedirs(label_dir, exist_ok=True)\n",
    "        \n",
    "        # Generate unique filename\n",
    "        filename = f'image_{idx}_{label_name}.jpg'\n",
    "        filepath = os.path.join(label_dir, filename)\n",
    "        \n",
    "        # Save image as RGB JPG\n",
    "        try:\n",
    "            img.convert('RGB').save(filepath, 'JPEG')\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving image {filename}: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # Track saved image details\n",
    "        saved_images.append({\n",
    "            'original_label': label,\n",
    "            'label_name': label_name,\n",
    "            'filename': filename,\n",
    "            'full_path': filepath\n",
    "        })\n",
    "    \n",
    "    # Optional: Create a log of saved images\n",
    "    log_path = os.path.join(output_base_dir, 'saved_images_log.csv')\n",
    "    pd.DataFrame(saved_images).to_csv(log_path, index=False)\n",
    "    \n",
    "    print(f\"Images saved to {output_base_dir}\")\n",
    "    print(f\"Saved images log: {log_path}\")\n",
    "    \n",
    "    return output_base_dir\n",
    "\n",
    "# Example usage\n",
    "# save_dataset_images(dataset, 'label_mapping.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images saved to dataset_images\n",
      "Saved images log: dataset_images\\saved_images_log.csv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dataset_images'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_dataset_images(dataset=dataset['train'], label_mapping_csv='label_names.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We have all the images downloaded into the dataset_images folder\n",
    "\n",
    "- Some findings\n",
    "    - There are some celebrities Like Zoe Zaldana and ZoE Zaldana who are the same person but have two folders assigned. \n",
    "    - The dataset doesnt have information of Gender. This is a challenge since when a user uploads an image and selects a gender and the app provides similarity to a different gender then it could negatively affect the sentiment of the user and consequently the app experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Assigning Gender using Genderize.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Function to get gender from Genderize API\n",
    "def get_gender(name):\n",
    "    url = \"https://api.genderize.io\"\n",
    "    first_name = name.split()[0]\n",
    "    params = {'name': first_name}\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        data = response.json()\n",
    "        gender = data.get('gender', 'Unknown') \n",
    "        print(f\"Request Completed : name:{name} firstName: {first_name} Gender:{gender}\")\n",
    "        return gender# Default to 'Unknown' if no gender found\n",
    "    except Exception as e:\n",
    "        return 'Error'  # Return 'Error' if request fails\n",
    "\n",
    "# Read the CSV file\n",
    "input_file = 'label_names.csv'  # Replace with your actual file path\n",
    "output_file = 'label_names_with_gender.csv'  # Output file path\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Ensure the DataFrame has 'Label' and 'Name' columns\n",
    "if 'Label' in df.columns and 'Name' in df.columns:\n",
    "    # Add a new column for gender\n",
    "    df_subset = df.head(100)\n",
    "    df_subset['GenderFN'] = df_subset['Name'].apply(get_gender)\n",
    "    \n",
    "    # Write the new DataFrame to a CSV file\n",
    "    df_subset.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file with Gender added has been saved as {output_file}\")\n",
    "else:\n",
    "    print(\"CSV file does not have required 'Label' and 'Name' columns.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We exhausted the daily quota. So trying with gender-guesser offline library\n",
    "```\n",
    "pip install pyGenderize\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file with gender added for first 100 rows has been saved as output_with_gender.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "# Initialize the gender detector\n",
    "d = gender.Detector()\n",
    "\n",
    "# Read the CSV file\n",
    "input_file = 'label_names.csv'  # Replace with your actual file path\n",
    "output_file = 'output_with_gender.csv'  # Output file path\n",
    "\n",
    "# Read the CSV into a DataFrame\n",
    "df = pd.read_csv(input_file)\n",
    "\n",
    "# Ensure the DataFrame has 'Label' and 'Name' columns\n",
    "if 'Label' in df.columns and 'Name' in df.columns:\n",
    "    # Function to get gender from the gender-guesser detector\n",
    "    def get_gender(name):\n",
    "        first_name = name.split()[0]  # Use only the first name\n",
    "        return d.get_gender(first_name)  # Returns 'male', 'female', 'mostly_male', 'mostly_female', 'unknown'\n",
    "    \n",
    "    # Apply the function to the 'Name' column\n",
    "    df['GenderGuesser'] = df['Name'].apply(get_gender)\n",
    "    \n",
    "    # Save the updated DataFrame to a new CSV file\n",
    "    df.to_csv(output_file, index=False)\n",
    "    print(f\"CSV file with gender added for first 100 rows has been saved as {output_file}\")\n",
    "else:\n",
    "    print(\"CSV file does not have required 'Label' and 'Name' columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysing results from gender-guesser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Name</th>\n",
       "      <th>GenderGuesser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Aaron Eckhart</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Aaron Paul</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Aaron Rodgers</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Aaron Taylor-Johnson</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Abbi Jacobson</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>992</th>\n",
       "      <td>992</td>\n",
       "      <td>Zoe Saldana</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>993</td>\n",
       "      <td>Zoey Deutch</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>994</th>\n",
       "      <td>994</td>\n",
       "      <td>Zooey Deschanel</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>Kravitz</td>\n",
       "      <td>unknown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>Zoe Saldana</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>997 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                   Name GenderGuesser\n",
       "0        0          Aaron Eckhart          male\n",
       "1        1             Aaron Paul          male\n",
       "2        2          Aaron Rodgers          male\n",
       "3        3   Aaron Taylor-Johnson          male\n",
       "4        4          Abbi Jacobson       unknown\n",
       "..     ...                    ...           ...\n",
       "992    992            Zoe Saldana        female\n",
       "993    993            Zoey Deutch        female\n",
       "994    994        Zooey Deschanel       unknown\n",
       "995    995                Kravitz       unknown\n",
       "996    996            Zoe Saldana        female\n",
       "\n",
       "[997 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "GenderGuesser\n",
       "male             429\n",
       "female           385\n",
       "unknown           87\n",
       "mostly_male       58\n",
       "mostly_female     31\n",
       "andy               7\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('output_with_gender.csv')\n",
    "display(df)\n",
    "\n",
    "unique_counts = df['GenderGuesser'].value_counts()\n",
    "display(unique_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We need some manual work to assign gender for around 150 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Name</th>\n",
       "      <th>GenderGuesser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>100</td>\n",
       "      <td>Blake Lively</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>111</td>\n",
       "      <td>Bryce Dallas Howard</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>114</td>\n",
       "      <td>Cameron Diaz</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>129</td>\n",
       "      <td>Charlie Cox</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>130</td>\n",
       "      <td>Charlie Day</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>131</td>\n",
       "      <td>Charlie Hunnam</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>132</td>\n",
       "      <td>Charlie Plummer</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>Chris Cooper</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>142</td>\n",
       "      <td>Chris Evans</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>143</td>\n",
       "      <td>Chris Hemsworth</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>144</td>\n",
       "      <td>Chris Martin</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>145</td>\n",
       "      <td>Chris Messina</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>146</td>\n",
       "      <td>Chris Noth</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>147</td>\n",
       "      <td>Chris O'Dowd</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>148</td>\n",
       "      <td>Chris Pine</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>149</td>\n",
       "      <td>Chris Pratt</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>150</td>\n",
       "      <td>Chris Tucker</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>Dakota Fanning</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>Dakota Johnson</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>231</td>\n",
       "      <td>Dylan O Brien</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>Freddie Highmore</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>Freddie Prinze Jr.</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>Hayden Panettiere</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>375</td>\n",
       "      <td>Jaden Smith</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>410</td>\n",
       "      <td>Javier Bardem</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>Jude Law</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>571</th>\n",
       "      <td>571</td>\n",
       "      <td>Kit Harington</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>595</td>\n",
       "      <td>Lee Pace</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>619</td>\n",
       "      <td>Logan Lerman</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>722</td>\n",
       "      <td>Morgan Freeman</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>800</td>\n",
       "      <td>Ray Liotta</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>801</td>\n",
       "      <td>Ray Romano</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>818</th>\n",
       "      <td>818</td>\n",
       "      <td>Riley Keough</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>828</td>\n",
       "      <td>Robin Tunney</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>829</td>\n",
       "      <td>Robin Williams</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>844</th>\n",
       "      <td>844</td>\n",
       "      <td>Ryan Eggold</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>845</th>\n",
       "      <td>845</td>\n",
       "      <td>Ryan Gosling</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>846</td>\n",
       "      <td>Ryan Murphy</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>847</td>\n",
       "      <td>Ryan Phillippe</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>848</td>\n",
       "      <td>Ryan Reynolds</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>849</td>\n",
       "      <td>Ryan Seacrest</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>851</td>\n",
       "      <td>Sam Claflin</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>852</td>\n",
       "      <td>Sam Heughan</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>853</td>\n",
       "      <td>Sam Rockwell</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>854</th>\n",
       "      <td>854</td>\n",
       "      <td>Sam Smith</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>867</td>\n",
       "      <td>Sasha Alexander</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>882</td>\n",
       "      <td>Shawn Mendes</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>910</td>\n",
       "      <td>Taylor Hill</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>911</td>\n",
       "      <td>Taylor Kitsch</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>912</td>\n",
       "      <td>Taylor Lautner</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>913</td>\n",
       "      <td>Taylor Schilling</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>914</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>933</td>\n",
       "      <td>Toby Jones</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>934</td>\n",
       "      <td>Toby Kebbell</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>935</th>\n",
       "      <td>935</td>\n",
       "      <td>Toby Regbo</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>963</th>\n",
       "      <td>963</td>\n",
       "      <td>Vin Diesel</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>973</th>\n",
       "      <td>973</td>\n",
       "      <td>Will Ferrell</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>974</td>\n",
       "      <td>Will Poulter</td>\n",
       "      <td>mostly_male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                  Name GenderGuesser\n",
       "100    100          Blake Lively   mostly_male\n",
       "111    111   Bryce Dallas Howard   mostly_male\n",
       "114    114          Cameron Diaz   mostly_male\n",
       "129    129           Charlie Cox   mostly_male\n",
       "130    130           Charlie Day   mostly_male\n",
       "131    131        Charlie Hunnam   mostly_male\n",
       "132    132       Charlie Plummer   mostly_male\n",
       "141    141          Chris Cooper   mostly_male\n",
       "142    142           Chris Evans   mostly_male\n",
       "143    143       Chris Hemsworth   mostly_male\n",
       "144    144          Chris Martin   mostly_male\n",
       "145    145         Chris Messina   mostly_male\n",
       "146    146            Chris Noth   mostly_male\n",
       "147    147          Chris O'Dowd   mostly_male\n",
       "148    148            Chris Pine   mostly_male\n",
       "149    149           Chris Pratt   mostly_male\n",
       "150    150          Chris Tucker   mostly_male\n",
       "179    179        Dakota Fanning   mostly_male\n",
       "180    180        Dakota Johnson   mostly_male\n",
       "231    231         Dylan O Brien   mostly_male\n",
       "296    296      Freddie Highmore   mostly_male\n",
       "297    297    Freddie Prinze Jr.   mostly_male\n",
       "343    343     Hayden Panettiere   mostly_male\n",
       "375    375           Jaden Smith   mostly_male\n",
       "410    410         Javier Bardem   mostly_male\n",
       "501    501              Jude Law   mostly_male\n",
       "571    571         Kit Harington   mostly_male\n",
       "595    595              Lee Pace   mostly_male\n",
       "619    619          Logan Lerman   mostly_male\n",
       "722    722        Morgan Freeman   mostly_male\n",
       "800    800            Ray Liotta   mostly_male\n",
       "801    801            Ray Romano   mostly_male\n",
       "818    818          Riley Keough   mostly_male\n",
       "828    828          Robin Tunney   mostly_male\n",
       "829    829        Robin Williams   mostly_male\n",
       "844    844           Ryan Eggold   mostly_male\n",
       "845    845          Ryan Gosling   mostly_male\n",
       "846    846           Ryan Murphy   mostly_male\n",
       "847    847        Ryan Phillippe   mostly_male\n",
       "848    848         Ryan Reynolds   mostly_male\n",
       "849    849         Ryan Seacrest   mostly_male\n",
       "851    851           Sam Claflin   mostly_male\n",
       "852    852           Sam Heughan   mostly_male\n",
       "853    853          Sam Rockwell   mostly_male\n",
       "854    854             Sam Smith   mostly_male\n",
       "867    867       Sasha Alexander   mostly_male\n",
       "882    882          Shawn Mendes   mostly_male\n",
       "910    910           Taylor Hill   mostly_male\n",
       "911    911         Taylor Kitsch   mostly_male\n",
       "912    912        Taylor Lautner   mostly_male\n",
       "913    913      Taylor Schilling   mostly_male\n",
       "914    914          Taylor Swift   mostly_male\n",
       "933    933            Toby Jones   mostly_male\n",
       "934    934          Toby Kebbell   mostly_male\n",
       "935    935            Toby Regbo   mostly_male\n",
       "963    963            Vin Diesel   mostly_male\n",
       "973    973          Will Ferrell   mostly_male\n",
       "974    974          Will Poulter   mostly_male"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mostly_male_df = df[df['GenderGuesser'] == 'mostly_male']\n",
    "\n",
    "# Display or save the result\n",
    "display(mostly_male_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TODO We need to complete this gender classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VGGFace2 as base model for face recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras_vggface.vggface import VGGFace\n",
    "from keras_vggface import utils"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSCN8010_classical_ml_311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
