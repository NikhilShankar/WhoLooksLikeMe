{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Image SImilarity Finder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\DELL\\Desktop\\Conestoga\\AIML\\FOML-FinalProject\\WhoLooksLikeMe\\venv\\tensorflow_facenet\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "(1, 299, 299, 3)\n",
      "InceptionV3 model loaded successfully!\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "from FaceNetModel import FaceNetModel\n",
    "import os\n",
    "from DataPreparation import DataPreparation\n",
    "from SimilarityCalculator import SimilarityCalculator\n",
    "\n",
    "original_data_dir = \"../dataset_images\"\n",
    "output_dir = \"train5\"\n",
    "sample_class_number = 5\n",
    "\n",
    "data_preparation = DataPreparation(original_data_dir, output_dir, sample_class_number)\n",
    "selected_classes = data_preparation.prepare_data()\n",
    "\n",
    "# Model training and embedding creation\n",
    "face_net_model = FaceNetModel()\n",
    "embeddings_dir = \"embeddings5\"\n",
    "if not os.path.exists(embeddings_dir):\n",
    "    os.makedirs(embeddings_dir)\n",
    "\n",
    "embeddings = face_net_model.create_embeddings_for_personality(f\"train-main/{output_dir}\", embeddings_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InceptionV3 model loaded successfully!\n",
      "Image shape after preprocessing: (1, 299, 299, 3)\n",
      "Most similar personality:  Maya Hawke with similarity score: 0.8368708491325378\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Maya Hawke</td>\n",
       "      <td>0.836871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lucy Lawless</td>\n",
       "      <td>0.813079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dave Grohl</td>\n",
       "      <td>0.631887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chace Crawford</td>\n",
       "      <td>0.610698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ryan Eggold</td>\n",
       "      <td>0.488564</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0       Maya Hawke  0.836871\n",
       "1     Lucy Lawless  0.813079\n",
       "2       Dave Grohl  0.631887\n",
       "3   Chace Crawford  0.610698\n",
       "4      Ryan Eggold  0.488564"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from SimilarityCalculator import SimilarityCalculator\n",
    "from FaceNetModel import FaceNetModel\n",
    "import pandas as pd\n",
    "\n",
    "# Similarity calculation\n",
    "face_net_model = FaceNetModel()\n",
    "embeddings_dir = \"embeddings5\"\n",
    "similarity_calculator = SimilarityCalculator(embeddings_dir)\n",
    "test_image_path = \"../test_image/maya.jpg\"\n",
    "similar_personality = similarity_calculator.calculate_similarity(test_image_path, face_net_model)\n",
    "\n",
    "df = pd.DataFrame(similar_personality)\n",
    "print(f\"Most similar personality: {similar_personality[0][0]} with similarity score: {similar_personality[0][1]}\")\n",
    "display(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_facenet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
